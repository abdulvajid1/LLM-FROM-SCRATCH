{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e0393a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as request\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import tiktoken\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dd2baa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f56ba29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.exists('data/verdict.txt'):\n",
    "#     file_path = 'theverdict.txt'\n",
    "#     url = (\"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch02/01_main-chapter-code/the-verdict.txt\")\n",
    "#     request.urlretrieve(url, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "65d9d427",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('theverdict.txt','r', encoding='utf-8') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea0bc54",
   "metadata": {},
   "source": [
    "## Tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d2115190",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fd70840d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[44488, 837, 266, 1929, 283, 1279, 91, 437, 91, 29]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('hai , wwhar <|end|>', allowed_special={'<|endoftext|>'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459d4d67",
   "metadata": {},
   "source": [
    "## Data Sampling with sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f448b4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_token = tokenizer.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "81802216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = [40, 367, 2885, 1464]\n",
      "labels =    [367, 2885, 1464, 1807]\n",
      "input = [367, 2885, 1464, 1807]\n",
      "labels =    [2885, 1464, 1807, 3619]\n",
      "input = [2885, 1464, 1807, 3619]\n",
      "labels =    [1464, 1807, 3619, 402]\n",
      "input = [1464, 1807, 3619, 402]\n",
      "labels =    [1807, 3619, 402, 271]\n",
      "input = [1807, 3619, 402, 271]\n",
      "labels =    [3619, 402, 271, 10899]\n"
     ]
    }
   ],
   "source": [
    "context_len = 4\n",
    "for i in range(5):\n",
    "    \n",
    "    input_token = enc_token[i :i + context_len]\n",
    "    labels = enc_token[i+1 : i+context_len+1]\n",
    "    \n",
    "    print(f\"input = {input_token}\")\n",
    "    print(f\"labels =    {labels}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f8ae50",
   "metadata": {},
   "source": [
    "## Coding Attention mechanism|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e02bbdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(torch.nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.q_W = torch.nn.Linear(d_model, d_model)\n",
    "        self.k_W = torch.nn.Linear(d_model, d_model)\n",
    "        self.v_W = torch.nn.Linear(d_model, d_model)\n",
    "        self.o_W = torch.nn.Linear(d_model, d_model)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        query = self.q_W(x)\n",
    "        key = self.k_W(x)\n",
    "        value = self.v_W(x)\n",
    "        attention_scores = query@key.T\n",
    "        attention_scores = torch.where(torch.tril(input=attention_scores)==0,torch.tensor(float('-inf')),torch.tril(input=attention_scores))\n",
    "        print(f\"before applying softmax:\")\n",
    "        print(attention_scores)\n",
    "        attention_scores = torch.softmax(attention_scores, dim=-1)\n",
    "        print(f\"after softmax\")\n",
    "        print(attention_scores)\n",
    "        contextualized_embedding = attention_scores@value\n",
    "        return contextualized_embedding\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a80fda31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4963, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.6341, 0.4901, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3489, 0.4017, 0.0223, 0.0000, 0.0000],\n",
       "        [0.5185, 0.6977, 0.8000, 0.1610, 0.0000]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tril(input=sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "32dc87bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4963, 0.7682, 0.0885, 0.1320, 0.3074],\n",
      "        [0.6341, 0.4901, 0.8964, 0.4556, 0.6323],\n",
      "        [0.3489, 0.4017, 0.0223, 0.1689, 0.2939],\n",
      "        [0.5185, 0.6977, 0.8000, 0.1610, 0.2823]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "sample = torch.rand((4,5))\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "2c1b1dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = SelfAttention(sample.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0d01deb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4963, 0.6341, 0.3489, 0.5185],\n",
       "        [0.7682, 0.4901, 0.4017, 0.6977],\n",
       "        [0.0885, 0.8964, 0.0223, 0.8000],\n",
       "        [0.1320, 0.4556, 0.1689, 0.1610],\n",
       "        [0.3074, 0.6323, 0.2939, 0.2823]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.transpose(-1, -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d841ef73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before applying softmax:\n",
      "tensor([[ 0.0922,    -inf,    -inf,    -inf],\n",
      "        [ 0.2716,  0.1647,    -inf,    -inf],\n",
      "        [-0.0206, -0.4406, -0.0593,    -inf],\n",
      "        [ 0.1061, -0.1440,  0.0595,  0.0009]], grad_fn=<WhereBackward0>)\n",
      "after softmax\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5267, 0.4733, 0.0000, 0.0000],\n",
      "        [0.3818, 0.2509, 0.3673, 0.0000],\n",
      "        [0.2752, 0.2143, 0.2627, 0.2478]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0873, -0.5075, -0.1755, -0.1140,  0.3443],\n",
       "        [ 0.0824, -0.5954, -0.1146, -0.2196,  0.1748],\n",
       "        [ 0.0391, -0.5315, -0.1859, -0.1900,  0.1965],\n",
       "        [ 0.0994, -0.5635, -0.1211, -0.1661,  0.1906]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1885988a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_x = torch.tensor([[ 9.2212e-02,  -1.0000e-18,  -1.0000e-18,  -1.0000e-18],\n",
    "                        [ 2.7157e-01,  1.6467e-01,  1.0000e-18,  1.0000e-18],\n",
    "                        [-2.0602e-02, -4.4060e-01, -5.9342e-02,  1.0000e-18],\n",
    "                        [ 1.0613e-01, -1.4402e-01,  5.9514e-02,  9.3780e-04]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e470e16c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2677, 0.2441, 0.2441, 0.2441],\n",
       "        [0.2921, 0.2625, 0.2227, 0.2227],\n",
       "        [0.2747, 0.1805, 0.2643, 0.2805],\n",
       "        [0.2752, 0.2143, 0.2627, 0.2478]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(torch_x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "88d01769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "72668318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2677, 0.2441, 0.2441, 0.2441],\n",
       "        [0.2921, 0.2625, 0.2227, 0.2227],\n",
       "        [0.2747, 0.1805, 0.2643, 0.2805],\n",
       "        [0.2752, 0.2143, 0.2627, 0.2478]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.softmax(torch_x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "cfd04a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.2212e-02, -1.0000e-18, -1.0000e-18, -1.0000e-18],\n",
       "        [ 2.7157e-01,  1.6467e-01,  1.0000e-18,  1.0000e-18],\n",
       "        [-2.0602e-02, -4.4060e-01, -5.9342e-02,  1.0000e-18],\n",
       "        [ 1.0613e-01, -1.4402e-01,  5.9514e-02,  9.3780e-04]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceff924",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
